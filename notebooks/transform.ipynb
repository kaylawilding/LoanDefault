{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.exceptions import NotFittedError\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataFrameOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Specialized version of OneHotEncoder that plays nice with pandas DataFrames and\n",
    "    will automatically set the feature/column names after fit/transform\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        categories=\"auto\",\n",
    "        drop=None,\n",
    "        sparse=None,\n",
    "        dtype=np.float64,\n",
    "        handle_unknown=\"error\",\n",
    "        col_overrule_params={},\n",
    "    ):\n",
    "        \"\"\"Create DataFrameOneHotEncoder that can be fitted to and transform dataframes\n",
    "        and that will set up the column/feature names automatically to\n",
    "        original_column_name[categorical_value]\n",
    "\n",
    "        If you provide the same arguments as you would for the sklearn \n",
    "        OneHotEncoder, these parameters will apply for all of the columns. If you want\n",
    "        to have specific overrides for some of the columns, provide these in the dict\n",
    "        argument col_overrule_params.\n",
    "        \n",
    "        For example:\n",
    "            DataFrameOneHotEncoder(col_overrule_params={\"col2\":{\"drop\":\"first\"}})\n",
    "\n",
    "        will create a OneHotEncoder for each of the columns with default values, but\n",
    "        uses a drop=first argument for columns with the name col2\n",
    "\n",
    "        Args:\n",
    "            categories‘auto’ or a list of array-like, default=’auto’\n",
    "                ‘auto’ : Determine categories automatically from the training data.\n",
    "                list : categories[i] holds the categories expected in the ith column.\n",
    "                The passed categories should not mix strings and numeric values\n",
    "                within a single feature, and should be sorted in case of numeric\n",
    "                values.\n",
    "            drop: {‘first’, ‘if_binary’} or a array-like of shape (n_features,),\n",
    "                default=None\n",
    "                See OneHotEncoder documentation\n",
    "            sparse: Ignored, since we always will work with dense dataframes\n",
    "            dtype: number type, default=float\n",
    "                Desired dtype of output.\n",
    "            handle_unknown: {‘error’, ‘ignore’}, default=’error’\n",
    "                Whether to raise an error or ignore if an unknown categorical feature\n",
    "                is present during transform (default is to raise). When this parameter\n",
    "                is set to ‘ignore’ and an unknown category is encountered during\n",
    "                transform, the resulting one-hot encoded columns for this feature will\n",
    "                be all zeros. In the inverse transform, an unknown category will be\n",
    "                denoted as None.\n",
    "            col_overrule_params: dict of {column_name: dict_params} where dict_params\n",
    "                are exactly the options cateogires,drop,sparse,dtype,handle_unknown.\n",
    "                For the column given by the key, these values will overrule the default\n",
    "                parameters\n",
    "        \"\"\"\n",
    "        self.categories = categories\n",
    "        self.drop = drop\n",
    "        self.sparse = sparse\n",
    "        self.dtype = dtype\n",
    "        self.handle_unknown = handle_unknown\n",
    "        self.col_overrule_params = col_overrule_params\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit a separate OneHotEncoder for each of the columns in the dataframe\n",
    "\n",
    "        Args:\n",
    "            X: dataframe\n",
    "            y: None, ignored. This parameter exists only for compatibility with\n",
    "                Pipeline\n",
    "\n",
    "        Returns\n",
    "            self\n",
    "\n",
    "        Raises\n",
    "            TypeError if X is not of type DataFrame\n",
    "        \"\"\"\n",
    "        if type(X) != pd.DataFrame:\n",
    "            raise TypeError(f\"X should be of type dataframe, not {type(X)}\")\n",
    "\n",
    "        self.onehotencoders_ = []\n",
    "        self.column_names_ = []\n",
    "\n",
    "        for c in X.columns:\n",
    "            # Construct the OHE parameters using the arguments\n",
    "            ohe_params = {\n",
    "                \"categories\": self.categories,\n",
    "                \"drop\": self.drop,\n",
    "                \"sparse\": False,\n",
    "                \"dtype\": self.dtype,\n",
    "                \"handle_unknown\": self.handle_unknown,\n",
    "            }\n",
    "            # and update it with potential overrule parameters for the current column\n",
    "            ohe_params.update(self.col_overrule_params.get(c, {}))\n",
    "\n",
    "            # Regardless of how we got the parameters, make sure we always set the\n",
    "            # sparsity to False\n",
    "            ohe_params[\"sparse\"] = False\n",
    "\n",
    "            # Now create, fit, and store the onehotencoder for current column c\n",
    "            ohe = OneHotEncoder(**ohe_params)\n",
    "            self.onehotencoders_.append(ohe.fit(X.loc[:, [c]]))\n",
    "\n",
    "            # Get the feature names and replace each x0_ with empty and after that\n",
    "            # surround the categorical value with [] and prefix it with the original\n",
    "            # column name\n",
    "            feature_names = ohe.get_feature_names()\n",
    "            feature_names = [x.replace(\"x0_\", \"\") for x in feature_names]\n",
    "            feature_names = [f\"{c}[{x}]\" for x in feature_names]\n",
    "\n",
    "            self.column_names_.append(feature_names)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform X using the one-hot-encoding per column\n",
    "\n",
    "        Args:\n",
    "            X: Dataframe that is to be one hot encoded\n",
    "\n",
    "        Returns:\n",
    "            Dataframe with onehotencoded data\n",
    "\n",
    "        Raises\n",
    "            NotFittedError if the transformer is not yet fitted\n",
    "            TypeError if X is not of type DataFrame\n",
    "        \"\"\"\n",
    "        if type(X) != pd.DataFrame:\n",
    "            raise TypeError(f\"X should be of type dataframe, not {type(X)}\")\n",
    "\n",
    "        if not hasattr(self, \"onehotencoders_\"):\n",
    "            raise NotFittedError(f\"{type(self).__name__} is not fitted\")\n",
    "\n",
    "        all_df = []\n",
    "\n",
    "        for i, c in enumerate(X.columns):\n",
    "            ohe = self.onehotencoders_[i]\n",
    "\n",
    "            transformed_col = ohe.transform(X.loc[:, [c]])\n",
    "\n",
    "            df_col = pd.DataFrame(transformed_col, columns=self.column_names_[i])\n",
    "            all_df.append(df_col)\n",
    "\n",
    "        return pd.concat(all_df, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('capstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f58c8666df6d98d75d0dc4ea8016d5e82eb5ad19e6e0a6b5c6df5035a9d16671"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
